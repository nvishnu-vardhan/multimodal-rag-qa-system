# ğŸ¤– Multi-Modal RAG QA System

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28-FF4B4B.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

An advanced **Multi-Modal Retrieval-Augmented Generation (RAG)** system designed to handle complex documents containing text, tables, images, charts, and figures. Built for real-world document intelligence challenges like financial reports, research papers, and technical manuals.

## ğŸ¯ Features

### ğŸ“¥ Multi-Modal Document Ingestion
- **PDF Processing**: Extract text, tables, charts, and images from PDFs
- **OCR Engine**: Handle scanned documents using PaddleOCR, Tesseract, and EasyOCR
- **Table Extraction**: Parse complex table structures with Camelot, Tabula, and PDFPlumber
- **Image Processing**: Analyze charts, diagrams, and figures
- **DOCX Support**: Process Word documents with full formatting

### ğŸ§  Intelligent Processing
- **Unified Embeddings**: Multi-modal vector space combining text and visual content
- **Semantic Chunking**: Context-aware document segmentation for optimal retrieval
- **Smart Retrieval**: Hybrid search combining dense and sparse methods
- **Cross-Modal Matching**: Find relevant information across different modalities

### ğŸ’¬ Interactive QA Interface
- **Context-Grounded Answers**: Responses strictly based on uploaded documents
- **Source Attribution**: Page and section-level citations for transparency
- **Multi-Turn Conversations**: Maintain context across multiple queries
- **Real-Time Processing**: Interactive document upload and processing

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Document Upload â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Multi-Modal Ingestion Layer    â”‚
â”‚  â”œâ”€ PDF Parser (PyMuPDF)         â”‚
â”‚  â”œâ”€ Table Extractor (Camelot)    â”‚
â”‚  â”œâ”€ OCR Engine (PaddleOCR)       â”‚
â”‚  â””â”€ Image Processor (PIL)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Chunking & Embedding Layer     â”‚
â”‚  â”œâ”€ Semantic Text Chunking        â”‚
â”‚  â”œâ”€ Table Structure Preservation  â”‚
â”‚  â”œâ”€ Image Caption Generation      â”‚
â”‚  â””â”€ CLIP Multi-Modal Embeddings   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Vector Store (ChromaDB)     â”‚
â”‚  â”œâ”€ Text Embeddings              â”‚
â”‚  â”œâ”€ Table Embeddings             â”‚
â”‚  â””â”€ Image Embeddings             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Retrieval & Generation        â”‚
â”‚  â”œâ”€ Query Embedding              â”‚
â”‚  â”œâ”€ Hybrid Retrieval (Top-K)    â”‚
â”‚  â”œâ”€ Context Assembly             â”‚
â”‚  â””â”€ LLM Generation (GPT-4)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Response with Citations          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- OpenAI API Key (for LLM)
- Tesseract OCR (optional, for advanced OCR)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/nvishnu-vardhan/multimodal-rag-qa-system.git
cd multimodal-rag-qa-system
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Set up environment variables**
```bash
cp .env.example .env
# Add your OpenAI API key to .env file
OPENAI_API_KEY=your_api_key_here
```

4. **Run the Streamlit app**
```bash
streamlit run app.py
```

5. **Open your browser**
```
http://localhost:8501
```

## ğŸ“– Usage

### 1. Upload Documents
- Click on the sidebar and upload your documents (PDF, DOCX, Images)
- Supports multiple file uploads

### 2. Configure Settings
- Enter your OpenAI API key
- Select LLM model (GPT-4, GPT-3.5-turbo, Gemini)
- Adjust chunk size and Top-K results

### 3. Process Documents
- Click "Process Documents" to start ingestion
- System will extract text, tables, and images
- Creates embeddings and stores in vector database

### 4. Ask Questions
- Type your question in the chat interface
- Receive context-grounded answers with citations
- View sources and page numbers for each answer

## ğŸ’» Project Structure

```
multimodal-rag-qa-system/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # Project documentation
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/              # Document ingestion modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document_parser.py  # Main document parser
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py    # PDF processing
â”‚   â”‚   â”œâ”€â”€ table_extractor.py  # Table extraction
â”‚   â”‚   â”œâ”€â”€ image_processor.py  # Image processing
â”‚   â”‚   â””â”€â”€ ocr_engine.py       # OCR functionality
â”‚   â”‚
â”‚   â”œâ”€â”€ chunking/               # Chunking strategies
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ text_chunker.py
â”‚   â”‚   â”œâ”€â”€ table_chunker.py
â”‚   â”‚   â””â”€â”€ semantic_chunker.py
â”‚   â”‚
â”‚   â”œâ”€â”€ embeddings/             # Embedding generation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ text_embeddings.py
â”‚   â”‚   â”œâ”€â”€ multimodal_embeddings.py
â”‚   â”‚   â””â”€â”€ clip_embeddings.py
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/              # Retrieval system
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â”œâ”€â”€ hybrid_search.py
â”‚   â”‚   â””â”€â”€ reranker.py
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/             # Answer generation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ qa_chain.py
â”‚   â”‚   â”œâ”€â”€ prompt_templates.py
â”‚   â”‚   â””â”€â”€ citation_builder.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ file_handler.py
â”‚       â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ data/                       # Data storage
â”‚   â”œâ”€â”€ uploads/               # Uploaded documents
â”‚   â”œâ”€â”€ processed/             # Processed data
â”‚   â””â”€â”€ vector_db/             # Vector database storage
â”‚
â”œâ”€â”€ tests/                      # Unit tests
â”‚   â”œâ”€â”€ test_ingestion.py
â”‚   â”œâ”€â”€ test_chunking.py
â”‚   â”œâ”€â”€ test_retrieval.py
â”‚   â””â”€â”€ test_generation.py
â”‚
â””â”€â”€ docs/                       # Additional documentation
    â”œâ”€â”€ ARCHITECTURE.md
    â”œâ”€â”€ API_REFERENCE.md
    â””â”€â”€ DEPLOYMENT.md
```

## ğŸ”§ Technology Stack

### Core Framework
- **Streamlit**: Interactive web interface
- **LangChain**: RAG pipeline orchestration
- **Python 3.8+**: Backend language

### LLM & Embeddings
- **OpenAI**: GPT-4, GPT-3.5-turbo
- **Sentence Transformers**: Text embeddings
- **CLIP**: Multi-modal embeddings
- **Google Gemini**: Alternative LLM support

### Document Processing
- **PyMuPDF (fitz)**: PDF parsing
- **PyPDF2**: PDF text extraction
- **python-docx**: Word document processing
- **Pillow**: Image processing

### Table Extraction
- **Camelot**: Advanced table extraction
- **Tabula**: PDF table parsing
- **PDFPlumber**: Layout-aware extraction
- **Pandas**: Data manipulation

### OCR Engines
- **PaddleOCR**: High-accuracy OCR
- **Tesseract**: Open-source OCR
- **EasyOCR**: Multi-language support

### Vector Database
- **ChromaDB**: Primary vector store
- **FAISS**: Fast similarity search
- **Pinecone**: Cloud vector database (optional)

## ğŸ“Š Use Cases

### ğŸ¦ Financial Analysis
Query annual reports, balance sheets, and financial statements with complex tables and charts.

### ğŸ”¬ Research Papers
Extract insights from academic papers with equations, figures, and citations.

### âš–ï¸ Legal Documents
Search through contracts, policies, and legal briefs with dense text and tables.

### ğŸ“˜ Technical Manuals
Find specific procedures, diagrams, and technical specifications.

### ğŸ“ˆ Business Intelligence
Analyze presentations, reports, and dashboards with mixed content types.

## ğŸ“ Assignment Compliance

This project fulfills all requirements of the Multi-Modal Document Intelligence RAG-Based QA System assignment:

### âœ… Features Implemented
- [x] Multi-modal ingestion (text, tables, images, OCR)
- [x] Unified multi-modal embedding space
- [x] Semantic and structural chunking
- [x] Interactive QA chatbot interface
- [x] Page and section-level citations
- [x] Context-grounded answer generation

### âœ… Deliverables
- [x] Well-structured, modular codebase
- [x] Streamlit demo application
- [x] Comprehensive documentation
- [x] Clear setup instructions

### ğŸ† Bonus Features
- Cross-modal retrieval
- Hybrid search with reranking
- Multiple LLM support (GPT-4, GPT-3.5, Gemini)
- Interactive statistics dashboard
- Document processing status tracking

## ğŸš§ Deployment

### Local Deployment
```bash
streamlit run app.py --server.port 8501
```

### Vercel Deployment
```bash
# Install Vercel CLI
npm install -g vercel

# Deploy
vercel
```

### Docker Deployment
```bash
# Build image
docker build -t multimodal-rag .

# Run container
docker run -p 8501:8501 multimodal-rag
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

**Vishnu Vardhan**
- GitHub: [@nvishnu-vardhan](https://github.com/nvishnu-vardhan)
- LinkedIn: [Connect with me](https://www.linkedin.com/in/nvishnu-vardhan)

## ğŸ™ Acknowledgments

- OpenAI for GPT models
- LangChain for RAG framework
- Streamlit for the amazing web framework
- The open-source community for various libraries

## ğŸ“š References

- [LangChain Documentation](https://python.langchain.com/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [OpenAI API](https://platform.openai.com/docs/)
- [ChromaDB Documentation](https://docs.trychroma.com/)

---

**Built with â¤ï¸ for advanced document intelligence**

â­ Star this repository if you find it helpful!
